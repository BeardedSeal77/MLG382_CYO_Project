{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76b1735",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "\n",
    "## Step 1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223394dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import kagglehub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857507f",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "\n",
    "## Step 2) Download Dataset\n",
    "\n",
    "the following script downloads and moves the dataset to root/Data/Raw\n",
    "\n",
    "set to `False` if you already have the dataset\n",
    "\n",
    "The incoming data for sales only holds sales for jan - feb, the sales forecasting models resolution will be on a weekly or daily scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d2208ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DOWNLOAD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd260520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download block skipped.\n"
     ]
    }
   ],
   "source": [
    "if RUN_DOWNLOAD:\n",
    "    # Download the dataset\n",
    "    download_path = kagglehub.dataset_download(\"bhanupratapbiswas/inventory-analysis-case-study\")\n",
    "\n",
    "    # Define the target directory\n",
    "    target_dir = os.path.abspath(\"../../Data/Raw\")\n",
    "\n",
    "    # Make sure the target directory exists\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # Move all files (not folders) from download_path to target_dir\n",
    "    for filename in os.listdir(download_path):\n",
    "        src = os.path.join(download_path, filename)\n",
    "        dst = os.path.join(target_dir, filename)\n",
    "\n",
    "        if os.path.isfile(src):\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "    print(\"Files moved to:\", target_dir)\n",
    "else:\n",
    "    print(\"Download block skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95363c0",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "\n",
    "## Step 3) Create Clean CSV files\n",
    "\n",
    "Start pulling data from dataset to produce clean csv files ready for the inventory ledger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56d9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "raw_path = '../../Data/Raw/'\n",
    "processed_path = '../../Data/Processed/'\n",
    "\n",
    "# Create processed directory if it doesn't exist\n",
    "os.makedirs(processed_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f2fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split composite InventoryId\n",
    "def split_inventory_id(df):\n",
    "    split_cols = df['InventoryId'].str.split('_', expand=True)\n",
    "    df['Store'] = split_cols[0]\n",
    "    df['Location'] = split_cols[1]\n",
    "    df['ItemId'] = split_cols[2]\n",
    "    df.drop(columns=['InventoryId'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866c26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edcul\\AppData\\Local\\Temp\\ipykernel_17924\\3327469519.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sales_cleaned['Store'] = sales_cleaned['Store'].astype(str).str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>SalesQuantity</th>\n",
       "      <th>SalesDate</th>\n",
       "      <th>ItemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2016</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2016</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/3/2016</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1/8/2016</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1/9/2016</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StoreID  SalesQuantity SalesDate ItemId\n",
       "0       1              1  1/1/2016   1004\n",
       "1       1              2  1/2/2016   1004\n",
       "2       1              1  1/3/2016   1004\n",
       "3       1              1  1/8/2016   1004\n",
       "4       1              2  1/9/2016   1005"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sales.csv (Store, ItemId, SalesQuantity, SalesDate)\n",
    "# Load the Sales.csv file\n",
    "sales_file = os.path.join(raw_path, 'SalesFINAL12312016.csv')\n",
    "sales_df = pd.read_csv(sales_file)\n",
    "\n",
    "# Clean Sales.csv\n",
    "# 1. Keep only relevant columns (no need for Location, it's handled in Stores.csv)\n",
    "sales_cleaned = sales_df[[\n",
    "    'InventoryId',\n",
    "    'Store',\n",
    "    'SalesQuantity',\n",
    "    'SalesDate'\n",
    "]]\n",
    "\n",
    "# 2. Strip whitespace and filter for stores \"1\" and \"2\"\n",
    "sales_cleaned['Store'] = sales_cleaned['Store'].astype(str).str.strip()\n",
    "sales_cleaned = sales_cleaned[sales_cleaned['Store'].isin(['1', '2'])]\n",
    "\n",
    "# Apply split function to separate the composite InventoryId\n",
    "sales_cleaned = split_inventory_id(sales_cleaned)\n",
    "\n",
    "# Drop the Location column after splitting the InventoryId\n",
    "sales_cleaned.drop(columns=['Location'], inplace=True)\n",
    "\n",
    "# Rename 'Store' column to 'StoreID'\n",
    "sales_cleaned.rename(columns={'Store': 'StoreID'}, inplace=True)\n",
    "\n",
    "# Save the cleaned Sales.csv\n",
    "sales_cleaned.to_csv(os.path.join(processed_path, 'Sales.csv'), index=False)\n",
    "\n",
    "sales_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca77ddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edcul\\AppData\\Local\\Temp\\ipykernel_17924\\2386600434.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  purchases_cleaned['Store'] = purchases_cleaned['Store'].astype(str).str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PODate</th>\n",
       "      <th>ReceivingDate</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>ItemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>5255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>8358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23</td>\n",
       "      <td>4233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>3830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>4670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StoreID      PODate ReceivingDate  Quantity ItemId\n",
       "3        1  2015-12-22    2016-01-01         6   5255\n",
       "6        1  2015-12-20    2016-01-01        12   8358\n",
       "9        1  2015-12-20    2016-01-01        23   4233\n",
       "10       1  2015-12-20    2016-01-01         6   3830\n",
       "40       1  2015-12-20    2016-01-01        11   4670"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Purchases.csv (Store, PODate, ReceivingDate, Quantity)\n",
    "# Load the Purchases.csv file\n",
    "purchases_file = os.path.join(raw_path, 'PurchasesFINAL12312016.csv')\n",
    "purchases_df = pd.read_csv(purchases_file)\n",
    "\n",
    "# Clean Purchases.csv\n",
    "# 1. Keep only relevant columns\n",
    "purchases_cleaned = purchases_df[[\n",
    "    'InventoryId',\n",
    "    'Store',\n",
    "    'PODate',\n",
    "    'ReceivingDate',\n",
    "    'Quantity'\n",
    "]]\n",
    "\n",
    "# 2. Strip whitespace and filter for stores \"1\" and \"2\"\n",
    "purchases_cleaned['Store'] = purchases_cleaned['Store'].astype(str).str.strip()\n",
    "purchases_cleaned = purchases_cleaned[purchases_cleaned['Store'].isin(['1', '2'])]\n",
    "\n",
    "# Apply split function\n",
    "purchases_cleaned = split_inventory_id(purchases_cleaned)\n",
    "\n",
    "# Drop the Location column after splitting the InventoryId\n",
    "purchases_cleaned.drop(columns=['Location'], inplace=True)\n",
    "\n",
    "# Rename 'Store' column to 'StoreID'\n",
    "purchases_cleaned.rename(columns={'Store': 'StoreID'}, inplace=True)\n",
    "\n",
    "# Save the cleaned Purchases.csv\n",
    "purchases_cleaned.to_csv(os.path.join(processed_path, 'Purchases.csv'), index=False)\n",
    "\n",
    "purchases_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ab395a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edcul\\AppData\\Local\\Temp\\ipykernel_17924\\2026519689.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  OpeningStock_Cleaned['Store'] = OpeningStock_Cleaned['Store'].astype(str).str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>onHand</th>\n",
       "      <th>startDate</th>\n",
       "      <th>ItemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StoreID  onHand   startDate ItemId\n",
       "0       1       8  2015-12-31     58\n",
       "1       1       7  2015-12-31     60\n",
       "2       1       6  2015-12-31     62\n",
       "3       1       3  2015-12-31     63\n",
       "4       1       6  2015-12-31     72"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create OpeningStock.csv (Store, Location, ItemId, onHand, startDate)\n",
    "# Load the beginning inventory file\n",
    "OpeningStock_file = os.path.join(raw_path, 'BegInvFINAL12312016.csv')\n",
    "OpeningStock_df = pd.read_csv(beg_inv_file)\n",
    "\n",
    "# 🧹 Clean BegInvFINAL12312016.csv\n",
    "# 1. Keep only relevant columns\n",
    "OpeningStock_Cleaned = OpeningStock_df[[\n",
    "    'InventoryId',\n",
    "    'Store',\n",
    "    'onHand',\n",
    "    'startDate'\n",
    "]]\n",
    "\n",
    "# 2. Strip whitespace from Store and keep only store \"1\" and \"2\"\n",
    "OpeningStock_Cleaned['Store'] = OpeningStock_Cleaned['Store'].astype(str).str.strip()\n",
    "OpeningStock_Cleaned = OpeningStock_Cleaned[OpeningStock_Cleaned['Store'].isin(['1', '2'])]\n",
    "\n",
    "# 3. Replace the startDate with 2015-12-31\n",
    "OpeningStock_Cleaned['startDate'] = '2015-12-31'\n",
    "\n",
    "# Apply split function\n",
    "OpeningStock_Cleaned = split_inventory_id(OpeningStock_Cleaned)\n",
    "\n",
    "# Drop the Location column after splitting the InventoryId\n",
    "OpeningStock_Cleaned.drop(columns=['Location'], inplace=True)\n",
    "\n",
    "# Rename 'Store' column to 'StoreID'\n",
    "OpeningStock_Cleaned.rename(columns={'Store': 'StoreID'}, inplace=True)\n",
    "\n",
    "# Save the cleaned beginning inventory\n",
    "OpeningStock_Cleaned.to_csv(os.path.join(processed_path, 'OpeningStock.csv'), index=False)\n",
    "\n",
    "OpeningStock_Cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eae574b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004</td>\n",
       "      <td>Jim Beam w/2 Rocks Glasses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Maker's Mark Combo Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10058</td>\n",
       "      <td>F Coppola Dmd Ivry Cab Svgn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1006</td>\n",
       "      <td>Jim Beam Candy Cane 4/50mLs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10062</td>\n",
       "      <td>Terroirs du Rhone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ItemID                  Description\n",
       "0     1004   Jim Beam w/2 Rocks Glasses\n",
       "4     1005      Maker's Mark Combo Pack\n",
       "8    10058  F Coppola Dmd Ivry Cab Svgn\n",
       "17    1006  Jim Beam Candy Cane 4/50mLs\n",
       "18   10062            Terroirs du Rhone"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Inventory.csv (ItemID, Description)\n",
    "# Pull ItemID and Description from original CSVs\n",
    "sales_info = sales_df[['Brand', 'Description']].rename(columns={'Brand': 'ItemID'})\n",
    "purchases_info = purchases_df[['Brand', 'Description']].rename(columns={'Brand': 'ItemID'})\n",
    "opening_info = OpeningStock_df[['Brand', 'Description']].rename(columns={'Brand': 'ItemID'})\n",
    "\n",
    "# Combine and deduplicate\n",
    "inventory_df = pd.concat([sales_info, purchases_info, opening_info])\n",
    "inventory_df.drop_duplicates(subset=['ItemID', 'Description'], keep='first', inplace=True)\n",
    "\n",
    "# Save Inventory Master file\n",
    "inventory_df.to_csv(os.path.join(processed_path, 'Inventory.csv'), index=False)\n",
    "\n",
    "inventory_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf38915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StoreID</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>2</td>\n",
       "      <td>ASHBORNE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StoreID      Location\n",
       "5         1  HARDERSFIELD\n",
       "305       2      ASHBORNE"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract InventoryID from a few datasets to make sure all inventory items are read\n",
    "\n",
    "beg_inv_file = os.path.join(raw_path, 'BegInvFINAL12312016.csv')\n",
    "tbl1df = pd.read_csv(beg_inv_file)\n",
    "\n",
    "purchases_file = os.path.join(raw_path, 'PurchasesFINAL12312016.csv')\n",
    "tbl2df = pd.read_csv(purchases_file)\n",
    "\n",
    "tbl1 = tbl1df['InventoryId'].dropna().unique()\n",
    "tbl2 = tbl2df['InventoryId'].dropna().unique()\n",
    "\n",
    "# Combine and deduplicate InventoryIDs\n",
    "ALLtbls = pd.Series(list(set(tbl1).union(set(tbl2))))\n",
    "\n",
    "# Filter only those entries that can be cleanly split into 3 parts\n",
    "ALLtbls_valid = ALLtbls[ALLtbls.str.count('_') == 2]\n",
    "\n",
    "# Split InventoryID into StoreID, Location, and ItemID\n",
    "stores_split = ALLtbls_valid.str.split('_', expand=True)\n",
    "stores_split.columns = ['StoreID', 'Location', 'ItemID']\n",
    "\n",
    "# Keep only stores 1 and 2\n",
    "stores_split = stores_split[stores_split['StoreID'].isin(['1', '2'])]\n",
    "\n",
    "# Create Stores DataFrame and drop duplicates\n",
    "stores_df = stores_split[['StoreID', 'Location']].drop_duplicates()\n",
    "\n",
    "# Save to CSV\n",
    "stores_df.to_csv(os.path.join(processed_path, 'Stores.csv'), index=False)\n",
    "\n",
    "stores_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
